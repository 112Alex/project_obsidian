#обучение #go #backend #программирование #REST #вайбкодинг
# **Бот для транскрибации длинных лекций и создания конспектов в Notion**
## 1. Стек

1. **Язык программирования и окружение**
    - Go (Golang) 1.25+
    - Docker
    - Docker Compose
2. **Базы данных и кэширование**
    - PostgreSQL (реляционная СУБД)
    - Redis (кэш и очередь сообщений)
3. **Внешние API и сервисы**
    - Telegram Bot API (через go-telegram-bot-api)
    - Notion API (официальный REST API)
    - OpenAI Whisper API (транскрибация аудио)
    - DeepSeek API (суммаризация текста)
4. **Библиотеки и фреймворки для Go**
    - Chi - легковесный HTTP-роутер
    - pgx - драйвер PostgreSQL для Go
    - go-redis - клиент Redis для Go
    - jomei/notionapi - клиент Notion API для Go
    - Viper - управление конфигурацией
    - Slog (встроенный в Go 1.21+) - структурированное логирование
5. **Системные утилиты**
    - FFmpeg - обработка и конвертация аудиофайлов
6. **Инфраструктура**
    - Docker - для простого развёртывания контейнеров
    - В будущем - Linux-хостинг или облачная платформа k8s (в перспективе)
7. **Прочие инструменты**
    - GitHub - система контроля версий
    - Prometheus + Grafana (опционально, для мониторинга)
    - Makefile (для автоматизации сборки)

---
## 2. Архитектура и дизайн системы

### Мы строим отказоустойчивый монолит с четким разделением ответственности (SOLID).

### Сущности в PostgreSQL:

1. **Пользователи (`users`)**
    - `id` SERIAL PRIMARY KEY
    - `telegram_id` BIGINT UNIQUE NOT NULL — парсим из сообщения.
    - `notion_api_key` TEXT — токен пользователя для Notion. _Пока храним здесь, но в будущем это нужно шифровать._
    - `notion_database_id` TEXT — ID базы данных в Notion, куда будут складываться конспекты.
    - `created_at` TIMESTAMP
    - `updated_at` TIMESTAMP
2. **Задачи (`jobs`)**
    - `id` SERIAL PRIMARY KEY
    - `user_id` INTEGER REFERENCES users(id) — связь с пользователем.
    - `status` ENUM('pending', 'processing', 'completed', 'failed') — статус задачи.
    - `audio_file_path` TEXT — путь к временному аудиофайлу.
    - `transcript_text` TEXT — сырой текст транскрибации.
    - `summary_markdown` TEXT — итоговый конспект в MD.
    - `notion_page_id` TEXT — ID созданной страницы в Notion (чтобы можно было потом обновлять).
    - `error_message` TEXT — сообщение об ошибке, если статус `failed`.
    - `created_at` TIMESTAMP
    - `updated_at` TIMESTAMP

	 Важно, что нужно делать всё для защиты от разного рода инъекций и взломов, а также оптимизировать БД (напр. исп. индексы)

### Очередь задач на Redis:

Для управления асинхронной обработкой мы будем использовать Redis в качестве очереди. Это надежнее, чем горутины с каналами, и переживет перезапуск бота.

- Воркер будет брать задачу из списка `lecture_jobs` в Redis.
- Это гарантирует, что ни одно сообщение не будет потеряно и обработано ровно один раз (в идеале).

### Процесс работы (Data Flow):

1. **Получение сообщения:** Пользователь отправляет боту аудиофайл (или голосовое сообщение).
2. **Сохранение и регистрация:** Бот сохраняет файл на диск (во временную папку `./tmp`). Создает запись в таблице `jobs` со статусом `pending` и помещает `job_id` в очередь Redis.
3. **Подтверждение:** Бот сразу же отвечает пользователю: "Аудио принято в обработку. Ждите уведомление о готовности." (Не заставляем пользователя ждать 10+ минут).
4. **Воркер (Асинхронная обработка):** Независимый воркер (в рамках того же приложения) постоянно мониторит очередь Redis.
    - Достает `job_id`, меняет статус задачи на `processing`.
    - **Предобработка:** Вызывает FFmpeg для конвертации аудио в формат WAV (16kHz, mono).
    - **Транскрибация:** Отправляет подготовленный файл в OpenAI Whisper API.
    - **Суммаризация:** Формирует промпт и отправляет полученный текст в DeepSeek API для создания краткого конспекта в формате Markdown.
    - **Создание страницы:** Конвертирует Markdown в блоки Notion с помощью собственного конвертера и создает новую страницу в базе данных пользователя (`notion_database_id`).
    - **Фиксация результата:** Сохраняет полученный `summary_markdown` и `notion_page_id` в БД. Меняет статус задачи на `completed`.
    - **Уведомление:** Отправляет пользователю в Telegram сообщение с ссылкой на созданную страницу в Notion. _Дополнительно можно прикрепить .md файл с конспектом, как резервную копию._
5. **Ошибка:** На любом этапе, в случае ошибки, статус задачи меняется на `failed`, ошибка пишется в БД, а пользователю отправляется сообщение с извинениями и описанием ошибки (для админа).

---
## 3. Про Notion и формат

- **Куда добавлять:** Вы абсолютно правы. Правильный подход — создать отдельную **базу данных (Database)** в Notion с названием "Конспекты бота" или подобным. База данных — это и есть та самая "папка" с расширенными возможностями: сортировка, фильтрация, теги, свойства (дата лекции, предмет и т.д.).
- **Формат:** Конспект будет создаваться в виде **страницы внутри этой базы данных**. Мы преобразуем Markdown от DeepSeek в родные **блоки Notion** (заголовки, параграфы, списки, code blocks). Это будет красиво, структурированно и очень удобно для чтения и дальнейшего редактирования. Это надежнее, чем просто прикрепленный .md-файл.

---
## 4. Docker-окружение

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15
    container_name: lecture_bot_db
    environment:
      POSTGRES_USER: bot_user
      POSTGRES_PASSWORD: ${DB_PASSWORD} # Пароль из .env файла
      POSTGRES_DB: lecture_bot
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: lecture_bot_redis
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    restart: unless-stopped

  bot:
    build: .
    container_name: lecture_bot
    environment:
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - NOTION_API_KEY=${NOTION_API_KEY} # Общий ключ, если не используется per-user
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - DATABASE_URL=postgresql://bot_user:${DB_PASSWORD}@postgres:5432/lecture_bot?sslmode=disable
      - REDIS_ADDR=redis:6379
    volumes:
      - ./tmp:/app/tmp # Монтируем папку для временных файлов
      - ./ffmpeg:/app/ffmpeg # Если FFmpeg не встроен в образ
    depends_on:
      - postgres
      - redis
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
```
### Файл .env с переменными окружения

```env
`TELEGRAM_BOT_TOKEN=ваш_токен`  
`DB_PASSWORD=ваш_сложный_пароль`  
`OPENAI_API_KEY=ваш_ключ`  
`DEEPSEEK_API_KEY=ваш_ключ`
```

---
## 5. План реализации ( roadmap )

1. **Настройка окружения:** Установить Docker Desktop на Windows, создать бота у @BotFather, получить API-ключи для OpenAI и DeepSeek.
2. **Инициализация проекта:** `go mod init`, создать структуру папок как выше.
3. **Реализация конфигурации:** Написать код загрузки config через Viper.
4. **Подключение к БД и Redis:** Написать функции инициализации подключений.
5. **Реализация телеграм-бота:** Написать обработчик входящих сообщений, который будет регистрировать пользователя и сохранять аудиофайлы.
6. **Реализация очереди задач:** Код для работы с Redis-очередью.
7. **Реализация воркера:** Код, который берет задание из очереди и последовательно выполняет шаги: FFmpeg -> Whisper -> DeepSeek -> Notion.
8. **Написание конвертера MD-to-Notion Blocks:** Самая сложная и творческая часть.
9. **Тестирование:** Протестировать весь пайплайн на одном файле.
10. **Написание Dockerfile и docker-compose.yml.**
11. **Деплой** на ПК и финальное тестирование.